{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.mllib.linalg.distributed import CoordinateMatrix, MatrixEntry\n",
    "from pyspark import SQLContext\n",
    "from pyspark.accumulators import AccumulatorParam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import time\n",
    "conf = SparkConf()\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBias(user, item):    # Bias btw. movie & user\n",
    "    isUser = train_pdsDF.iloc[:, 0]==user\n",
    "    isItem = train_pdsDF.iloc[:, 1]==item\n",
    "\n",
    "    user_avg =  train_pdsDF[isUser]['Rating'].sum() / train_pdsDF[isUser].shape[0]\n",
    "    user_bias = user_avg - global_avg\n",
    "\n",
    "    item_avg = train_pdsDF[isItem]['Rating'].sum() / train_pdsDF[isItem].shape[0]\n",
    "    item_bias = item_avg - global_avg\n",
    "\n",
    "    user_item_bias = user_bias + item_bias + global_avg\n",
    "    return user_item_bias\n",
    "def getMovieID(idx, movie):     # Return the one is not equal to the movie in (user,movie)\n",
    "    if simPdsDF[\"ItemID_1\"][idx] == movie:\n",
    "        return simPdsDF[\"ItemID_2\"][idx]\n",
    "    else:\n",
    "        return simPdsDF[\"ItemID_1\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredict(user, movie, top_k):\n",
    "    # Get all similar movies\n",
    "    is_ItemID_1_Sim = simPdsDF['ItemID_1'] == movie\n",
    "    is_ItemID_2_Sim = simPdsDF['ItemID_2'] == movie\n",
    "    is_Sim_PdsDF = simPdsDF[is_ItemID_1_Sim | is_ItemID_2_Sim]\n",
    "\n",
    "    if len(is_Sim_PdsDF.index) < 1:  # New Item in Test.dat\n",
    "        print('user: ', user, 'movie: ', movie, 'is_Sim_PdsDF.index < 1')\n",
    "        return global_avg          \n",
    "\n",
    "    # Get rated index\n",
    "    isRatedIdx = []\n",
    "    for idx in is_Sim_PdsDF.index:\n",
    "        MovieID = getMovieID(idx, movie)\n",
    "        if (user, MovieID) in train_dict:\n",
    "            isRatedIdx.append(idx)\n",
    "\n",
    "    # Sorted rated movies by similarity (from high to low)\n",
    "    isRatedPdsDF = simPdsDF.iloc[isRatedIdx, :]\n",
    "    isRatedPdsDF = isRatedPdsDF.sort_values(by = ['Similarity'], ascending = False)\n",
    "\n",
    "    # Compute predicted rating by top_k similar movies\n",
    "    Sim_total = 0\n",
    "    Up_total = 0\n",
    "    Bias_movie = getBias(user, movie)\n",
    "    if isRatedPdsDF.shape[0]<top_k:\n",
    "        top_k = isRatedPdsDF.shape[0]\n",
    "    for k in range(top_k):\n",
    "        MovieID_k = getMovieID(isRatedPdsDF.index[k], movie)\n",
    "        Rating_k = train_dict[(user, MovieID_k)]\n",
    "        Sim_k = isRatedPdsDF.iloc[k, 2]  # Column 2 is similairty, isRatedPdsDF is sorted by similairty\n",
    "        Bias_k = getBias(user, MovieID_k)\n",
    "        Up_total += Sim_k*(Rating_k - Bias_k)\n",
    "        Sim_total += Sim_k\n",
    "    PredRating = Bias_movie + (Up_total/Sim_total)\n",
    "    return PredRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorAccumulatorParam(AccumulatorParam):\n",
    "    def zero(self, value):\n",
    "        return [0.0]*len(value)\n",
    "    def addInPlace(self, val1, val2):   #val1: list\n",
    "        val1 += val2\n",
    "        return val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get actual rating\n",
    "def test_spilt_result(x):  # x[0]:user, x[1]:item, x[2]:rating \n",
    "    global ans\n",
    "    global top_k\n",
    "    PredRating = getPredict(x[0], x[1], top_k)\n",
    "    ans += [[x[0], x[1], PredRating]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "real_train_pdsDF = pd.read_csv('train.dat', sep = \",\")\n",
    "top_k = 51\n",
    "for train, test in kf.split(real_train_pdsDF):\n",
    "    start_time = time.time()\n",
    "    #------------------------------------------------- Split train to trian_split, test_split\n",
    "    train_spilt_pdsDF = real_train_pdsDF.iloc[train, :]\n",
    "    test_spilt_pdsDF = real_train_pdsDF.iloc[test, :]\n",
    "    train_spilt_pdsDF.to_csv('train_split.dat', sep = \",\", index = False)\n",
    "    test_spilt_pdsDF.to_csv('test_spilt.dat', sep = \",\", index = False)\n",
    "    \n",
    "    #------------------------------------------------- Read test_split file to rdd\n",
    "    test_spilt_lines = sc.textFile(\"test_spilt.dat\")\n",
    "    header = test_spilt_lines.first()\n",
    "    test_spilt_lines = test_spilt_lines.filter(lambda line: line != header)\n",
    "    test_spilt_rdd = test_spilt_lines.map(lambda line: line.split(',')).map(\n",
    "            lambda tokens: (int(tokens[0]),int(tokens[1]),int(tokens[2])))\n",
    "    global test_spilt_dict\n",
    "    test_spilt_dict = {}\n",
    "    for x, y, z in test_spilt_rdd.collect():\n",
    "        test_spilt_dict[(x, y)] = z\n",
    "    \n",
    "    #------------------------------------------------- Read train_split file to rdd\n",
    "    train_lines = sc.textFile(\"train_split.dat\")\n",
    "    header = train_lines.first()\n",
    "    train_lines = train_lines.filter(lambda line: line != header)\n",
    "    global train_rdd\n",
    "    train_rdd = train_lines.map(lambda line: line.split(',')).map(\n",
    "                lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2])))\n",
    "    # Build Train Data Dict. with Format [(user, item)] = rating\n",
    "    # for later check if the specific movie is rated\n",
    "    global train_dict\n",
    "    train_dict = {}\n",
    "    for x, y, z in train_rdd.collect():\n",
    "        train_dict[(x, y)] = z\n",
    "    \n",
    "    # ----------------------------------------------------------- Build simMat&simPdsDF\n",
    "    sqlCon = SQLContext(sc)\n",
    "    utilityMatrix = CoordinateMatrix(train_rdd)\n",
    "    # Similarity Btw. Items\n",
    "    simMat = utilityMatrix.toRowMatrix().columnSimilarities()\n",
    "    # Convert simMat to Pandas format\n",
    "    global simPdsDF\n",
    "    sparkDF = simMat.entries.map(lambda x: str(x.i)+\",\"+str(x.j)+\",\"+str(x.value)).map(lambda w: w.split(',')).toDF()\n",
    "    simPdsDF = sparkDF.toPandas()\n",
    "    # edit columns' name\n",
    "    simPdsDF.columns = ['ItemID_1', 'ItemID_2', 'Similarity']\n",
    "    # change data type\n",
    "    simPdsDF['ItemID_1'] = simPdsDF['ItemID_1'].astype(int)\n",
    "    simPdsDF['ItemID_2'] = simPdsDF['ItemID_2'].astype(int)\n",
    "    simPdsDF['Similarity'] = simPdsDF['Similarity'].astype(float)\n",
    "    # ------------------------------------------------------ Used for RDD to calculate bias\n",
    "    global train_pdsDF\n",
    "    train_pdsDF = pd.read_csv('train_split.dat', sep = \",\")\n",
    "    train_pdsDF = train_pdsDF.drop(\"Timestamp\", axis=1)\n",
    "    global global_avg    # overall mean rating\n",
    "    global_sum = train_pdsDF['Rating'].sum()\n",
    "    global_avg = global_sum/train_pdsDF.shape[0]\n",
    "    # ------------------------------------------------------Get predicted rating of Test.dat \n",
    "    ans = sc.accumulator([], VectorAccumulatorParam())\n",
    "    test_spilt_rdd.foreach(test_spilt_result)\n",
    "    ans = np.array(ans.value)\n",
    "    targetList = list(zip(ans[:, 0], ans[:, 1]))\n",
    "    y_actual = []\n",
    "    for target in targetList:\n",
    "        y_actual.append(test_spilt_dict[target])\n",
    "    y_predict = ans[:, 2]\n",
    "    #-------------------------------------------------------- Calculate RMSE\n",
    "    rms = sqrt(mean_squared_error(y_actual, y_predict))\n",
    "    print(\"k: %s, RMSE: %s\" % (top_k, rms))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    top_k += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''k: 51, RMSE: 0.9337310790949384\n",
    "--- 1351.5924348831177 seconds ---\n",
    "k: 56, RMSE: 0.9385368190877761\n",
    "--- 1357.0452268123627 seconds ---\n",
    "k: 61, RMSE: 0.9276684827030836\n",
    "--- 1403.6028318405151 seconds ---'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "k: 30, RMSE: 0.9346116908876994\n",
    "--- 957.2602119445801 seconds ---\n",
    "k: 40, RMSE: 0.9262036293252163\n",
    "--- 1151.4687297344208 seconds ---\n",
    "k: 50, RMSE: 0.9257627541958798\n",
    "--- 1305.7629108428955 seconds ---\n",
    "k: 60, RMSE: 0.923157020767258\n",
    "--- 1527.7708637714386 seconds ---\n",
    "k: 70, RMSE: 0.9354237971076579\n",
    "--- 1763.168536901474 seconds ---'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''k: 4, RMSE: 0.9761079319227415\n",
    "--- 460.2000787258148 seconds ---\n",
    "k: 6, RMSE: 0.9552355889053802\n",
    "--- 479.1455092430115 seconds ---\n",
    "k: 8, RMSE: 0.9319697215787797\n",
    "--- 537.9487290382385 seconds ---'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
